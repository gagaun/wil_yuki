#### 케라스 창시자에게 배우는 딥러닝
___

### 3장. 신경망 시작하기
___

#### 3.1 신경망의 구조
* 네트워크를 구성하는 **층**
* **입력데이터**와 그에 상응하는 **타깃**
* 학습에 사용할 피드백 신호를 정의하는 **손실함수**
* 학습 진행 방식을 결정하는 **옵티마이저**

##### 층: 딥러닝의 구성 단위
- 하나 이상의 텐서를 입력으로 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈
- 층은 가중치라는 상태를 가진다.
- 가중치는 확률적 경사 하강법에 의해 학습되는 하나 이상의 텐서

##### 모델: 층의 네트워크
- 네트워크 구조는 가설 공간을 정의

##### 손실함수와 옵티마이저 : 학습 과정을 조절하는 열쇠
- keras  :
  - https://keras.io/losses/
  - https://keras.io/optimizers/
- loss, activation, optimizer 함수 한글 설명 블로그 :
  - https://woosa7.github.io/DL00/
  - http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html


#### 3.2 케라스
- 거의 모든 종류의 딥러닝 모델을 간편하게 만들고 훈련시킬 수 있는 파이썬을 위한 딥러닝 프레임워크.
  - 동일한 코드로 cpu 와 gpu 에서 실행할 수 있음.
  - 쉬운 api 제공
  - 합성곱 신경망, 순환 신경망을 지원하며 조합이 자유로움
  - 어떤 네트워크 구조도 만들 수 있으므로 기본적으로 어떤 딥러닝 모델에도 적합함.
- MIT 라이선스를 따르므로 상업적인 프로젝트에도 자유롭게 사용 가능


#### 3.4 ~ 3.6 이진 분류, 다중 분류, 회귀 예제

##### 케라스를 이용한 개발 흐름
1. 데이터셋 로드   데이터를 텐서 (벡터)로 변환
2. 신경망 모델 구성
  - 층 구성 - activation 함수 등 설정
  - 검증 구성 - optimiser, loss function 등 설정
3. model 훈련
4. 훈련 검증
  - 훈련 데이터에서 샘플을 추출해 검증
  - 성능을 측정하고 과대적합을 피하기 위함


##### 데이터셋 로드
- 본 예제의 데이터셋들은 keras 라이브러리로 정의되어  load_data 함수로 로드 가능함.
  - num_words :  빈도 순위로 몇번째에 해당하는 데이터까지 가져올 것인가를 정의. None 으로 설정하면 모든 단어를 데이터로 가져옴
  - test_split:  몇퍼센트의 데이터를 테스트셋으로 사용할 것인지 정의

- 데이터셋을 훈련, 테스트 2벌 준비하는 이유 :
  - 같은 데이터로 머신 러닝 모델을 훈련하고 테스트하는 것은 의미가 없다.
  - 훈련 후 새로운 테스트 데이터에서의 모델 수행 결과와 성능이 의미가 있다.
  - 20000 개의 데이터가 있으면 18,000개는 훈련용, 2,000개는 테스트용으로 보류한채 훈련 시킬때는 사용하지 않을 수 있다.

##### 신경망 구성
###### 전처리 :text to tensor
  - 책 4.3.1 에서 데이터 전처리(벡터화, 정규화 등)에 대해 설명
  - 텍스트 벡터화(원핫인코딩, 단어 임베딩 등)에 대해서는 책 6.1에서 자세히 설명

###### One-Hot Encoding  https://wikidocs.net/22647
```
"나는 자연어 처리를 배운다" // 형태소 분석기 split 처리
word2index = {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}
one_hot_encoding("자연어",word2index)
[0, 0, 1, 0, 0, 0] // one_hot_vector
```
- 단어 집합의 크기를 벡터의 크기로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식.
- 이렇게 표현된 벡터를 원-핫 벡터(One-hot vector)라고 한다.
- 한계
  - 인덱스로 표현할 단어의 갯수가 증가할수록 벡터의 차원이 계속 증가
  - 원-핫 벡터는 모든 개별 단어가 하나의 인덱스로 표현되기 때문에 단어의 유사성을 표현하지 못함.
  - 다차원의 공간에 벡터화하여 문제 해결
    - LSA : 카운트 기반으로 단어의 의미를 벡터화
    - NNLM,RNNLM,CBOW,skip-gram : 신경망으로 단어의 의미를 벡터화 https://wikidocs.net/22660


###### Dense  https://tykimos.github.io/2017/01/27/MLP_Layer_Talk/
- 입력과 출력을 연결해주는 레이어 (전결합층)
- 케라스에서는 Dense라는 클래스로 구현
- Dense(8, input_dim=4, init=‘uniform’, activation=‘relu’)
  - Param1 출력 뉴런의 수 설정 ( 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. )
  - Input_dim = 입력 뉴런의 수
  - Init: 가중치 초기화 방법 :
    - uniform - 균일분포
    - normal - 가우시안분포
  - Activation : 활성화함수
    - ‘linear’ : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.
    - ‘relu’ : rectifier 함수, 은닉층에 주로 쓰입니다.
    - ‘sigmoid’ : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다.
    - ‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다.


##### 훈련 검증
- 원본 훈련 데이터에서 일정 분량의 샘플을 떼어서 검증 세트를 만듦
- 적정 횟수의 에포크 동안 훈련시키는 동시에 따로 떼어 놓은 검증 샘플에서 손실과 정확도를 측정한다.
- 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 함
```
model.fit(partial_x_train,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_val, y_val))
```

- model.fit() 메서드에서 반환한 history 객체를 matplot 을 활용해 훈련과 검증 데이터에 대한 손실과 정확도 그래프를 그릴 수 있다.
- 훈련 데이터에 과도하게 최적화되어 과대 적합 되지 않도록 주의
- 훈련 횟수 최적점을 찾아 새로운 신경망 구성
